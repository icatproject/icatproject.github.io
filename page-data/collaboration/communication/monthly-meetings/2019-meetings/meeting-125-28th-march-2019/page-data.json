{"componentChunkName":"component---src-templates-default-jsx","path":"/collaboration/communication/monthly-meetings/2019-meetings/meeting-125-28th-march-2019/","result":{"data":{"markdownRemark":{"html":"<h2>Attendees:</h2>\n<p>Alex de Maria (AM), Brian Ritchie (BR), Stuart Pullinger (SP), Rolf\r\nKrahl (RK), Chris Prosser (CP), Silvie Da Graca Ramos (SR), Louise\r\nDavies (LD), George Christian (GC), Andy, Maxime</p>\n<h2><strong>Component Updates</strong></h2>\n<h3>ICAT server (SP):</h3>\n<ul>\n<li>Released 4.10.0 `icat-server` and `icat-client`</li>\n<li>Schema changes:\n<ul>\n<li>Added pid and enddate to Study</li>\n<li>Rofl’s schema changes</li>\n<li>Need to run schema upgrade scripts to upgrade</li>\n<li>Only additions to schema, minor changes needed</li>\n</ul>\n</li>\n<li>Issues:\n<ul>\n<li>Steve used MireDot to generate REST API docs</li>\n<li>Licence has experied – awaiting a new licence</li>\n<li>Proprietry software but free for open source</li>\n<li>Will generate docs for previous releases once this has happened</li>\n<li>Waffle.io (used for kanban board) is closing</li>\n<li>Move issues across to Github Projects</li>\n</ul>\n</li>\n</ul>\n<h3>IDS (RK):</h3>\n<ul>\n<li>Snapshot releases for `ids-server`, `ids-plugin`,\r\n`ids-plugin-file`\n<ul>\n<li>main change: support for file system locking\n<ul>\n<li>if plugin decides to implement, allows for concurrent access\r\nto storage</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h3>Python-ICAT (RK):</h3>\n<ul>\n<li>Released `python-icat` 0.15.0\n<ul>\n<li>Supports icat-server schema changes</li>\n<li>Fixes some compatibility issues</li>\n<li>Last version to support Python 2.6</li>\n</ul>\n</li>\n</ul>\n<p>Q: Andy: python 2.6 support dropped – will 2.7 still be supported?</p>\n<p>RK: When python-icat v1 is released, likely will drop support for Python\r\n2 then, following on discussions on the mailing list</p>\n<p>SP: scripts in icat-server are Python 2 only, so work needed to convert\r\nto python 3<br>\nShould we convert to support both or just support python 3?<br>\nRH6 only has python 2 as default, so sensible to make them support both</p>\n<p>RK: shouldn’t be too hard to support both for small scripts</p>\n<p>SP: aim to support both</p>\n<h3>Topcat (BR):</h3>\n<ul>\n<li>Released topcat 2.4.3\n<ul>\n<li>contains schema changes from icat-server 4.10.0</li>\n<li>Minor change from last snapshots: remove spinners for cells that\r\nare blank</li>\n<li>component updates in vagrant/travis build</li>\n<li>Travis still sporiadically fails, some attempts have been made\r\nbut no definitive fix</li>\n</ul>\n</li>\n</ul>\n<h2><strong>Site Updates</strong></h2>\n<h3>DLS (CP):</h3>\n<ul>\n<li>2 mechanisms for user recall: standard HTTPS and Globus/PollCAT –\r\nlots of user recalls on both\n<ul>\n<li>\n<p>HTTPS: 2 user recalls had issues to do with tape, IDS timed out,\r\nscript normally restarts recall but the scripts didn’t have\r\nenough storage to retrieve the files – resolved by restarting\r\nIDS</p>\n</li>\n<li></li>\n<li>\n<p>GLOBUS: millions of files requested/several TB of data, swamped\r\nIDS, made us reconsider PollCAT design</p>\n</li>\n</ul>\n</li>\n<li>Everything else seems fine</li>\n</ul>\n<p>SR:</p>\n<ul>\n<li>changing ingest – putting into pre-prod soon</li>\n</ul>\n<p>Q: Andy – how many times do you copy data when moved in the Globus\r\nsystem?</p>\n<p>SR – Diamond uses datafile and not dataset level storage</p>\n<p>SP – Scans table in TopCAT directly for downloads marked as Globus, and\r\nignores HTTPS. Files are copied from tape to StorageD, then copied to\r\nIDS main storage, then copied into separate Globus download area</p>\n<p>SR – google group mailing issue about copying data might seem similar,\r\nbut believe Diamond issue is separate</p>\n<p>Andy – tape storage managers want to reduce copies to only 1 copy rather\r\nthan 3</p>\n<p>RK – IDS has intermediate step if you have dataset where archive is\r\ncopied to cache, and then it is extracted to main, datafile does not\r\nhave this step. This extra step has been an issue from 2016, but it is\r\ndifficult. Would like to refactor some code in IDS before tackling this\r\nissue, so no promises of when a fix will happen. You will still have 2\r\ncopies – 1 in archive and 1 in main, this is hard to avoid.</p>\n<p>Q: AM – can we restore data automatically into main area?</p>\n<p>RK – no</p>\n<p>Andy – “restore to original place” – aka main storage</p>\n<p>RK – IDS doesn’t know about tape storage, so it must request from tape\r\nfirst, it is built with archive and main. Client request comes in, IDS\r\ntriggers restore, reads ZIP from archive and restores to main.</p>\n<p>SP – can storage system unzip to main behind IDS’s back? IDS checks if\r\nit is on disk first, before it goes to archive and if it’s available it\r\ncan use it. If ids-plugin isn’t responsible for restoring, and a\r\nseparate system unzips?</p>\n<p>RK – would need to talk directly to tape storage, but then would need to\r\ncode all backends. No direct communication between IDS-server and\r\nstorage backend. IDS talks to main storage plugin and then archive\r\nstorage plugin. No direct way to avoid this.</p>\n<h3>HZB (RK):</h3>\n<ul>\n<li>Nothing to report</li>\n</ul>\n<h2><strong>AOB</strong></h2>\n<h3>Diamond recall bug</h3>\n<p>SP – Diamond problems with restarting recall where IDS needs to be\r\nrestarted – seems similar to bug (issue #87) where IDS locked files\r\nwhen recalling, but if thread crashed then the files would remain locked\r\nuntil IDS restarted. Check Diamond has a version of IDS which includes\r\nthis bugfix and if it doesn’t then upgrade.</p>\n<p>RK – fixed in IDS 1.9.1</p>\n<h3>Plugin Logging</h3>\n<p>SP – Diamond StorageD plugin, most ids-plugins don’t have much logging.\r\nRK’s student has solution to get logging in plugins?</p>\n<p>RK – You can use logging in the plugins, using log4j, one caveat: you\r\nneed to provide a logfile config that shadows logfile from IDS-server.\r\nInconvenient because logging for IDS-server is in plugin, but it works.</p>\n<p>SP – where is this fix recorded?</p>\n<p>RK – issue #76, some documentation in this issue</p>\n<p>SP – next version of IDS may require recompilation for plugins, so might\r\nbe a good idea to look at logging now to save multiple recompilations</p>\n<p>RK – away for next 2 weeks, but after may provide information on how to\r\nmodify plugins delete should not throw exception then file to delete\r\ndoes not exist additional call lock. Suggest adding these things to\r\narchive storage, otherwise need to add dummy method</p>\n<h3>Moving instead of copying in Diamond</h3>\n<p>CP – Manually deleting data from IDS, response from RK that this isn’t a\r\ngood idea. Want to move data from IDS cache</p>\n<p>SP – on globus IDS files are restored from archive to main like normal\r\nIDS, these files are then copied to separate Globus area. Can we just\r\nmove them instead of copying? Problem: 2 requests for same file, IDS\r\nthinks it’s there for second file but file has been moved by request for\r\nfirst file</p>\n<p>RK – clarify: you want to move files from main storage to transfer area?\r\nThis is a problem as IDS doesn’t know file is not there. IDS might\r\nrestore things twice. Can you not make a hard link?</p>\n<p>Silvia – Is it possible to change permissions in main storage area so\r\nusers can access?</p>\n<p>SP – Globus has its own user, don’t know how this will work with\r\npermissions, but hard link might work</p>\n<p>RK – hard link will only work if both areas are on same file system</p>\n<p>Silvia – IDS has functionality to remove files when we want, different\r\nprocess to perform</p>\n<p>CP – user1/user2 causing double recall from archive is fine, this is\r\nrare case and offset by increase in move efficiency</p>\n<p>RK – should be fine, deleting files from datafile level storage is fine</p>\n<p>CP – so move works, but less efficient in multiple users requesting same\r\nfile</p>\n<p>Silvia – hard link might be useful for multiple users case</p>\n<p>RK – you can make hardlinks for file to users area, when IDS removes\r\nfile from main storage this will also remove hard links. Still have to\r\ncheck that permissions are separate between hardlinks and not shared.</p>\n<h3>Dataset level issue</h3>\n<p>SP: RK is proposing change when zip requested from archive, when files\r\ndon’t exist in zip or there are unexpected files, throw exceptions.\r\nConcern this is not suitable for ESRF where it ma be better to continue\r\nworking and log errors instead. Is there a comprimise – e.g. config\r\noption?</p>\n<p>AM: Understand RK’s POV, but this is the best we can do. Sometimes\r\npeople rename files and it’s impossible to find files. So we’d like to\r\nmake best effort to restore what we can.</p>\n<p>RK: you should make it consistent</p>\n<p>AM: you are imposing this constraint</p>\n<p>RK: IDS fundamentally relies that the data in ICAT is correct. If data\r\nis not correct you don’t get reliable. If the files in the ZIP don’t\r\nmatch then the data is not correct. IDS ignores files with null\r\nlocation.</p>\n<p>AM: we like that the location has a record of where it was</p>\n<p>RK: location is controlled by IDS, if it’s not then IDS is unstable</p>\n<p>SP: is it true that to accommodate RK’s change, you need to scan all\r\nfiles to check that they match what IDS expects – this is a big job</p>\n<p>AM: this isn’t too much of a worry, the worry is removing location that\r\nis useful to the user</p>\n<p>RK: location isn’t supposed to e useful for user, meant to be\r\nadministrative field for IDs to use</p>\n<p>AM: would prefer not to delete location – our IDS is working well</p>\n<p>RK: you will run into strange errors: restore will get stuck with an\r\nerror. IDS relies on location, if it’s not correct then IDS is not\r\ncorrect</p>\n<p>SP: could IDS be written that if file is missing you throw the error, in\r\nthe catch you check config option and skip this file, otherwise rethrow\r\nexception</p>\n<p>RK: you could do this, but doesn’t remove problem that IDS assumes\r\nlocation is correct and exists</p>\n<p>SP: ICAT/Diamond doesn’t have this problem because datafile level\r\nstorage</p>\n<p>RK: IDS will still file if it doesn’t exist</p>\n<p>SP: But if it fails for 1 file it will continue to next file, unlike\r\ndataset storage.</p>\n<p>AM: might be possible to use own field/parameter to record the previous\r\nlocation, then location can be nulled</p>\n<p>SP: look at how ingest works and look for inconsistency, look for skips</p>","frontmatter":{"title":"Meeting 125 – 28th March 2019","date":"2019-03-28T00:00:00.000Z"}}},"pageContext":{"slug":"/collaboration/communication/monthly-meetings/2019-meetings/meeting-125-28th-march-2019/"}},"staticQueryHashes":["2186722355","3212510956","3248290905","3649515864","4121107168"],"slicesMap":{}}